{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples of creating and operating distributions in Pixyz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fe4600389b0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import numpy as np\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pixyz.distributions import Normal\n",
    "from pixyz.utils import print_latex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dim = 20\n",
    "y_dim = 30\n",
    "z_dim = 40\n",
    "a_dim = 50\n",
    "batch_n = 2\n",
    "\n",
    "class P1(Normal):\n",
    "    def __init__(self):\n",
    "        super(P1, self).__init__(cond_var=[\"y\", \"a\"], var=[\"x\"], name=\"p_{1}\")\n",
    "\n",
    "        self.fc1 = nn.Linear(y_dim, 10)\n",
    "        self.fc2 = nn.Linear(a_dim, 10)\n",
    "        self.fc21 = nn.Linear(10+10, 20)\n",
    "        self.fc22 = nn.Linear(10+10, 20)\n",
    "\n",
    "    def forward(self, a, y):\n",
    "        h1 = F.relu(self.fc1(y))\n",
    "        h2 = F.relu(self.fc2(a))\n",
    "        h12 = torch.cat([h1, h2], 1)\n",
    "        return {\"loc\": self.fc21(h12), \"scale\": F.softplus(self.fc22(h12))}\n",
    "\n",
    "class P2(Normal):\n",
    "    def __init__(self):\n",
    "        super(P2, self).__init__(cond_var=[\"x\", \"y\"], var=[\"z\"], name=\"p_{2}\")\n",
    "\n",
    "        self.fc3 = nn.Linear(x_dim, 30)\n",
    "        self.fc4 = nn.Linear(30+y_dim, 400)\n",
    "        self.fc51 = nn.Linear(400, 20)\n",
    "        self.fc52 = nn.Linear(400, 20)\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        h3 = F.relu(self.fc3(x))\n",
    "        h4 = F.relu(self.fc4(torch.cat([h3, y], 1)))\n",
    "        return {\"loc\": self.fc51(h4), \"scale\": F.softplus(self.fc52(h4))}\n",
    "    \n",
    "p4 = Normal(loc=torch.tensor(0.), scale=torch.tensor(1.), var=[\"a\"], features_shape=[a_dim], name=\"p_{4}\")\n",
    "p6 = Normal(loc=torch.tensor(0.), scale=torch.tensor(1.), var=[\"y\"], features_shape=[y_dim], name=\"p_{6}\")\n",
    "    \n",
    "x = torch.from_numpy(np.random.random((batch_n, x_dim)).astype(\"float32\"))\n",
    "y = torch.from_numpy(np.random.random((batch_n, y_dim)).astype(\"float32\"))\n",
    "a = torch.from_numpy(np.random.random((batch_n, a_dim)).astype(\"float32\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = P1()\n",
    "p2 = P2()\n",
    "p3 = p2 * p1\n",
    "p3.name = \"p_{3}\"\n",
    "p5 = p3 * p4\n",
    "p5.name = \"p_{5}\"\n",
    "p_all = p1*p2*p4*p6\n",
    "p_all.name = \"p_{all}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution:\n",
      "  p_{1}(x|y,a)\n",
      "Network architecture:\n",
      "  P1(\n",
      "    name=p_{1}, distribution_name=Normal,\n",
      "    var=['x'], cond_var=['y', 'a'], input_var=['y', 'a'], features_shape=torch.Size([])\n",
      "    (fc1): Linear(in_features=30, out_features=10, bias=True)\n",
      "    (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "    (fc21): Linear(in_features=20, out_features=20, bias=True)\n",
      "    (fc22): Linear(in_features=20, out_features=20, bias=True)\n",
      "  )\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle p_{1}(x|y,a)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(p1)\n",
    "print_latex(p1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution:\n",
      "  p_{2}(z|x,y)\n",
      "Network architecture:\n",
      "  P2(\n",
      "    name=p_{2}, distribution_name=Normal,\n",
      "    var=['z'], cond_var=['x', 'y'], input_var=['x', 'y'], features_shape=torch.Size([])\n",
      "    (fc3): Linear(in_features=20, out_features=30, bias=True)\n",
      "    (fc4): Linear(in_features=60, out_features=400, bias=True)\n",
      "    (fc51): Linear(in_features=400, out_features=20, bias=True)\n",
      "    (fc52): Linear(in_features=400, out_features=20, bias=True)\n",
      "  )\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle p_{2}(z|x,y)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(p2)\n",
    "print_latex(p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution:\n",
      "  p_{2}(z,x|y,a) = p_{2}(z|x,y)p_{1}(x|y,a)\n",
      "Network architecture:\n",
      "  p_{1}(x|y,a):\n",
      "  P1(\n",
      "    name=p_{1}, distribution_name=Normal,\n",
      "    var=['x'], cond_var=['y', 'a'], input_var=['y', 'a'], features_shape=torch.Size([])\n",
      "    (fc1): Linear(in_features=30, out_features=10, bias=True)\n",
      "    (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "    (fc21): Linear(in_features=20, out_features=20, bias=True)\n",
      "    (fc22): Linear(in_features=20, out_features=20, bias=True)\n",
      "  )\n",
      "  p_{2}(z|x,y):\n",
      "  P2(\n",
      "    name=p_{2}, distribution_name=Normal,\n",
      "    var=['z'], cond_var=['x', 'y'], input_var=['x', 'y'], features_shape=torch.Size([])\n",
      "    (fc3): Linear(in_features=20, out_features=30, bias=True)\n",
      "    (fc4): Linear(in_features=60, out_features=400, bias=True)\n",
      "    (fc51): Linear(in_features=400, out_features=20, bias=True)\n",
      "    (fc52): Linear(in_features=400, out_features=20, bias=True)\n",
      "  )\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle p_{2}(z,x|y,a) = p_{2}(z|x,y)p_{1}(x|y,a)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(p3)\n",
    "print_latex(p3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution:\n",
      "  p_{4}(a)\n",
      "Network architecture:\n",
      "  Normal(\n",
      "    name=p_{4}, distribution_name=Normal,\n",
      "    var=['a'], cond_var=[], input_var=[], features_shape=torch.Size([50])\n",
      "    (loc): torch.Size([1, 50])\n",
      "    (scale): torch.Size([1, 50])\n",
      "  )\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle p_{4}(a)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(p4)\n",
    "print_latex(p4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution:\n",
      "  p_{2}(z,x,a|y) = p_{2}(z|x,y)p_{1}(x|y,a)p_{4}(a)\n",
      "Network architecture:\n",
      "  p_{4}(a):\n",
      "  Normal(\n",
      "    name=p_{4}, distribution_name=Normal,\n",
      "    var=['a'], cond_var=[], input_var=[], features_shape=torch.Size([50])\n",
      "    (loc): torch.Size([1, 50])\n",
      "    (scale): torch.Size([1, 50])\n",
      "  )\n",
      "  p_{1}(x|y,a):\n",
      "  P1(\n",
      "    name=p_{1}, distribution_name=Normal,\n",
      "    var=['x'], cond_var=['y', 'a'], input_var=['y', 'a'], features_shape=torch.Size([])\n",
      "    (fc1): Linear(in_features=30, out_features=10, bias=True)\n",
      "    (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "    (fc21): Linear(in_features=20, out_features=20, bias=True)\n",
      "    (fc22): Linear(in_features=20, out_features=20, bias=True)\n",
      "  )\n",
      "  p_{2}(z|x,y):\n",
      "  P2(\n",
      "    name=p_{2}, distribution_name=Normal,\n",
      "    var=['z'], cond_var=['x', 'y'], input_var=['x', 'y'], features_shape=torch.Size([])\n",
      "    (fc3): Linear(in_features=20, out_features=30, bias=True)\n",
      "    (fc4): Linear(in_features=60, out_features=400, bias=True)\n",
      "    (fc51): Linear(in_features=400, out_features=20, bias=True)\n",
      "    (fc52): Linear(in_features=400, out_features=20, bias=True)\n",
      "  )\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle p_{2}(z,x,a|y) = p_{2}(z|x,y)p_{1}(x|y,a)p_{4}(a)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(p5)\n",
    "print_latex(p5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution:\n",
      "  p_{1}(x,y,a,z) = p_{2}(z|x,y)p_{1}(x|y,a)p_{4}(a)p_{6}(y)\n",
      "Network architecture:\n",
      "  p_{6}(y):\n",
      "  Normal(\n",
      "    name=p_{6}, distribution_name=Normal,\n",
      "    var=['y'], cond_var=[], input_var=[], features_shape=torch.Size([30])\n",
      "    (loc): torch.Size([1, 30])\n",
      "    (scale): torch.Size([1, 30])\n",
      "  )\n",
      "  p_{4}(a):\n",
      "  Normal(\n",
      "    name=p_{4}, distribution_name=Normal,\n",
      "    var=['a'], cond_var=[], input_var=[], features_shape=torch.Size([50])\n",
      "    (loc): torch.Size([1, 50])\n",
      "    (scale): torch.Size([1, 50])\n",
      "  )\n",
      "  p_{1}(x|y,a):\n",
      "  P1(\n",
      "    name=p_{1}, distribution_name=Normal,\n",
      "    var=['x'], cond_var=['y', 'a'], input_var=['y', 'a'], features_shape=torch.Size([])\n",
      "    (fc1): Linear(in_features=30, out_features=10, bias=True)\n",
      "    (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "    (fc21): Linear(in_features=20, out_features=20, bias=True)\n",
      "    (fc22): Linear(in_features=20, out_features=20, bias=True)\n",
      "  )\n",
      "  p_{2}(z|x,y):\n",
      "  P2(\n",
      "    name=p_{2}, distribution_name=Normal,\n",
      "    var=['z'], cond_var=['x', 'y'], input_var=['x', 'y'], features_shape=torch.Size([])\n",
      "    (fc3): Linear(in_features=20, out_features=30, bias=True)\n",
      "    (fc4): Linear(in_features=60, out_features=400, bias=True)\n",
      "    (fc51): Linear(in_features=400, out_features=20, bias=True)\n",
      "    (fc52): Linear(in_features=400, out_features=20, bias=True)\n",
      "  )\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle p_{1}(x,y,a,z) = p_{2}(z|x,y)p_{1}(x|y,a)p_{4}(a)p_{6}(y)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(p_all)\n",
    "print_latex(p_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> torch.Size([30, 20])\n",
      "<class 'torch.Tensor'> torch.Size([30])\n",
      "<class 'torch.Tensor'> torch.Size([400, 60])\n",
      "<class 'torch.Tensor'> torch.Size([400])\n",
      "<class 'torch.Tensor'> torch.Size([20, 400])\n",
      "<class 'torch.Tensor'> torch.Size([20])\n",
      "<class 'torch.Tensor'> torch.Size([20, 400])\n",
      "<class 'torch.Tensor'> torch.Size([20])\n",
      "<class 'torch.Tensor'> torch.Size([10, 30])\n",
      "<class 'torch.Tensor'> torch.Size([10])\n",
      "<class 'torch.Tensor'> torch.Size([10, 50])\n",
      "<class 'torch.Tensor'> torch.Size([10])\n",
      "<class 'torch.Tensor'> torch.Size([20, 20])\n",
      "<class 'torch.Tensor'> torch.Size([20])\n",
      "<class 'torch.Tensor'> torch.Size([20, 20])\n",
      "<class 'torch.Tensor'> torch.Size([20])\n"
     ]
    }
   ],
   "source": [
    "for param in p3.parameters():\n",
    "     print(type(param.data), param.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': tensor([[-0.9833, -1.0652,  0.4239,  0.8173, -0.2204,  0.4001,  1.3073, -0.9367,\n",
       "           0.4676,  0.0725, -0.8273, -0.6580,  0.6714, -1.1744, -1.8351, -0.7814,\n",
       "           0.7336,  0.1674,  0.3620,  0.0546],\n",
       "         [-0.2711, -0.6360,  0.0101,  2.1712,  0.6242,  0.4904, -0.8587,  0.4797,\n",
       "          -0.9147,  1.8677,  0.5589, -0.3913, -0.5078,  0.8452,  0.7145,  1.1389,\n",
       "           0.3086, -0.6795,  0.0261,  0.2041]])}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p1.sample({\"a\":a, \"y\":y}, return_all=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': tensor([[[ 2.4950e-01,  3.1602e-01,  1.3576e-01, -5.6682e-01,  1.4176e+00,\n",
       "           -1.2555e+00,  1.0424e+00, -1.7783e-01,  1.2008e+00, -6.7176e-01,\n",
       "            8.4457e-01,  6.5844e-01,  7.3068e-05, -3.6145e-01,  1.6219e+00,\n",
       "            3.5318e-01,  1.6454e+00, -8.1888e-01,  9.0467e-01, -8.9661e-01],\n",
       "          [ 2.1985e+00,  1.4022e-01, -3.2016e-01,  4.7673e-01,  2.9189e-01,\n",
       "            7.5498e-01,  3.5511e-01, -5.0099e-01,  6.3490e-03, -8.2951e-01,\n",
       "            2.2636e-03,  8.9336e-01,  1.0691e+00, -3.2212e-01,  9.7468e-01,\n",
       "           -1.4594e+00,  1.3640e+00, -1.0668e+00, -6.6085e-01,  3.0555e-01]],\n",
       " \n",
       "         [[ 4.0230e-01,  4.0447e-01,  1.1434e+00,  4.1433e-02, -2.8270e-01,\n",
       "            4.2656e-01,  2.7652e-02, -1.2106e+00,  5.0271e-01, -8.8879e-01,\n",
       "           -2.3366e-01,  2.6811e-01,  5.8011e-01, -5.2861e-01,  6.5424e-01,\n",
       "            7.1672e-01,  2.6231e+00, -2.7531e-01,  1.1890e+00,  3.6978e-01],\n",
       "          [-4.0754e-01, -1.8754e+00,  1.1188e+00,  2.2412e-01,  1.4475e-01,\n",
       "            3.3415e-02,  2.6217e-01, -1.5937e+00,  1.3369e-01,  1.5222e-01,\n",
       "           -6.8367e-01,  3.6704e-02, -8.8265e-01, -3.7909e-01,  4.5045e-01,\n",
       "            1.0794e+00, -1.2454e+00,  2.4192e-01,  3.5277e-01,  2.6734e-01]],\n",
       " \n",
       "         [[-2.7008e-01, -5.0564e-03,  6.7867e-01, -2.5104e-01, -1.0751e-01,\n",
       "           -1.2973e+00,  1.7815e-01,  9.6819e-01,  1.2461e+00,  8.3197e-01,\n",
       "           -5.8201e-01,  1.3728e+00, -1.6051e-01,  1.4689e-01,  4.0101e-01,\n",
       "            4.8688e-01, -1.3050e+00, -1.0109e-01,  6.7988e-01, -2.7308e-01],\n",
       "          [-1.5496e+00, -1.0159e-01, -8.4485e-01,  1.6472e-01,  9.2197e-02,\n",
       "            5.9888e-01,  2.5445e-01, -9.0643e-01, -3.1996e-02,  4.9702e-01,\n",
       "           -1.4746e-01, -8.8091e-01, -1.1103e+00,  4.3571e-01, -1.1444e+00,\n",
       "            7.4381e-01,  8.0320e-01, -5.3139e-01, -3.0091e-01, -1.4306e+00]],\n",
       " \n",
       "         [[-1.9572e-01, -7.1475e-02, -5.6127e-01,  5.0729e-01,  7.7141e-01,\n",
       "            1.1320e+00,  2.4163e-01, -1.0681e+00,  4.7077e-01,  1.8429e+00,\n",
       "            1.3821e-01,  4.7555e-01,  1.6223e-01, -2.7979e-02, -1.4833e-02,\n",
       "           -5.6179e-01,  8.4451e-01,  8.3657e-02,  7.3867e-01,  6.3748e-01],\n",
       "          [-1.0380e+00, -1.4945e-01,  1.1591e-01, -2.1415e-01,  4.1904e-01,\n",
       "           -1.7778e+00, -4.3875e-01, -1.4673e-01,  9.0041e-01, -7.9586e-01,\n",
       "            6.8001e-01,  5.9753e-01, -9.6155e-02,  2.7519e-01,  1.1439e+00,\n",
       "           -5.3537e-01,  1.0087e-01,  1.1117e-01,  5.6056e-01,  5.8618e-01]],\n",
       " \n",
       "         [[-1.5349e-01, -5.5229e-01, -7.1991e-01,  4.7844e-01, -4.6586e-02,\n",
       "            7.8583e-01,  3.5390e-02, -1.4571e-02, -2.5198e-01, -1.5734e+00,\n",
       "           -1.2179e+00,  9.3774e-01, -6.9344e-01, -6.5871e-01,  1.2430e+00,\n",
       "            4.4307e-01, -2.5002e-01, -1.4566e+00, -1.5579e-01, -3.0742e-01],\n",
       "          [ 9.0831e-01, -1.7709e-01,  8.5224e-01, -3.3199e-01,  2.8839e-01,\n",
       "            1.1318e-01, -1.1650e-01, -1.0804e+00,  7.0902e-01,  7.8602e-02,\n",
       "           -3.2784e-01,  3.5550e-01, -5.2183e-01, -1.2722e+00, -1.2779e+00,\n",
       "            1.2328e+00,  1.5755e+00, -5.4039e-01, -1.9262e-02, -4.7284e-01]]])}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p1.sample({\"a\":a, \"y\":y}, sample_shape=[5], return_all=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': tensor([[0.2873, 0.9435, 0.1231, 0.2204, 0.6657, 0.5794, 0.0838, 0.2769, 0.6844,\n",
       "          0.1111, 0.7587, 0.8047, 0.0507, 0.9262, 0.2786, 0.1218, 0.6858, 0.6872,\n",
       "          0.2060, 0.1119, 0.5898, 0.1417, 0.5471, 0.3720, 0.8313, 0.9112, 0.6975,\n",
       "          0.7669, 0.0205, 0.5423, 0.7177, 0.6533, 0.9923, 0.3031, 0.6046, 0.6131,\n",
       "          0.2235, 0.6828, 0.2267, 0.3587, 0.8634, 0.8237, 0.4217, 0.2676, 0.1127,\n",
       "          0.1590, 0.5252, 0.5577, 0.5843, 0.3678],\n",
       "         [0.2433, 0.8302, 0.8332, 0.7060, 0.4069, 0.3686, 0.9766, 0.3705, 0.1188,\n",
       "          0.6160, 0.1727, 0.4442, 0.7902, 0.4048, 0.5020, 0.3769, 0.8155, 0.1155,\n",
       "          0.0530, 0.4988, 0.0719, 0.5762, 0.7310, 0.0912, 0.5370, 0.7789, 0.1860,\n",
       "          0.7515, 0.0460, 0.2896, 0.2969, 0.2924, 0.7538, 0.5971, 0.0058, 0.8062,\n",
       "          0.3838, 0.0946, 0.9118, 0.6873, 0.9220, 0.3024, 0.2468, 0.2095, 0.5070,\n",
       "          0.6059, 0.3747, 0.6300, 0.8308, 0.1317]]),\n",
       " 'y': tensor([[0.4487, 0.0598, 0.7338, 0.3522, 0.7955, 0.7567, 0.8746, 0.3631, 0.7995,\n",
       "          0.2807, 0.9368, 0.0192, 0.9368, 0.8792, 0.2240, 0.1647, 0.9051, 0.8877,\n",
       "          0.4056, 0.9226, 0.9058, 0.5873, 0.9171, 0.7015, 0.2538, 0.4920, 0.3192,\n",
       "          0.5458, 0.0588, 0.0675],\n",
       "         [0.9459, 0.8521, 0.0066, 0.4740, 0.8384, 0.5122, 0.0363, 0.2689, 0.6294,\n",
       "          0.0306, 0.6115, 0.2558, 0.4377, 0.0827, 0.0874, 0.6609, 0.6415, 0.0991,\n",
       "          0.4069, 0.6617, 0.9121, 0.0812, 0.1757, 0.2514, 0.3985, 0.0874, 0.2304,\n",
       "          0.8469, 0.6807, 0.7081]]),\n",
       " 'x': tensor([[ 1.3214, -0.5108, -1.1832,  1.2707,  0.3510,  0.0094,  1.2354, -1.2248,\n",
       "           0.2608,  1.3280, -0.4841,  0.8385,  0.4420, -1.1517,  0.1530,  0.4012,\n",
       "          -0.0713,  1.0429, -0.5651,  0.5723],\n",
       "         [ 1.0861,  0.3208,  1.0370, -0.4717,  0.4309,  0.0477, -0.1078,  0.2645,\n",
       "          -0.0410, -0.6860, -1.0014,  0.9727,  0.2289, -1.0252, -1.0819, -1.1254,\n",
       "          -0.1921, -0.1354,  1.6005, -0.7985]])}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p1.sample({\"a\":a, \"y\":y}, return_all=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\log p_{1}(x|y,a)\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\log p_{1}(x|y,a)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p1_log_prob = p1.log_prob()\n",
    "print(p1_log_prob)\n",
    "print_latex(p1_log_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-25.0882, -25.9153], grad_fn=<SumBackward1>)\n"
     ]
    }
   ],
   "source": [
    "outputs = p1.sample({\"y\": y, \"a\": a})\n",
    "print(p1_log_prob.eval(outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-25.0042, -24.5120], grad_fn=<SumBackward1>)\n"
     ]
    }
   ],
   "source": [
    "outputs = p2.sample({\"x\":x, \"y\":y})\n",
    "print(p2.log_prob().eval(outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'y': tensor([[0.4487, 0.0598, 0.7338, 0.3522, 0.7955, 0.7567, 0.8746, 0.3631, 0.7995,\n",
      "         0.2807, 0.9368, 0.0192, 0.9368, 0.8792, 0.2240, 0.1647, 0.9051, 0.8877,\n",
      "         0.4056, 0.9226, 0.9058, 0.5873, 0.9171, 0.7015, 0.2538, 0.4920, 0.3192,\n",
      "         0.5458, 0.0588, 0.0675],\n",
      "        [0.9459, 0.8521, 0.0066, 0.4740, 0.8384, 0.5122, 0.0363, 0.2689, 0.6294,\n",
      "         0.0306, 0.6115, 0.2558, 0.4377, 0.0827, 0.0874, 0.6609, 0.6415, 0.0991,\n",
      "         0.4069, 0.6617, 0.9121, 0.0812, 0.1757, 0.2514, 0.3985, 0.0874, 0.2304,\n",
      "         0.8469, 0.6807, 0.7081]]), 'a': tensor([[0.2873, 0.9435, 0.1231, 0.2204, 0.6657, 0.5794, 0.0838, 0.2769, 0.6844,\n",
      "         0.1111, 0.7587, 0.8047, 0.0507, 0.9262, 0.2786, 0.1218, 0.6858, 0.6872,\n",
      "         0.2060, 0.1119, 0.5898, 0.1417, 0.5471, 0.3720, 0.8313, 0.9112, 0.6975,\n",
      "         0.7669, 0.0205, 0.5423, 0.7177, 0.6533, 0.9923, 0.3031, 0.6046, 0.6131,\n",
      "         0.2235, 0.6828, 0.2267, 0.3587, 0.8634, 0.8237, 0.4217, 0.2676, 0.1127,\n",
      "         0.1590, 0.5252, 0.5577, 0.5843, 0.3678],\n",
      "        [0.2433, 0.8302, 0.8332, 0.7060, 0.4069, 0.3686, 0.9766, 0.3705, 0.1188,\n",
      "         0.6160, 0.1727, 0.4442, 0.7902, 0.4048, 0.5020, 0.3769, 0.8155, 0.1155,\n",
      "         0.0530, 0.4988, 0.0719, 0.5762, 0.7310, 0.0912, 0.5370, 0.7789, 0.1860,\n",
      "         0.7515, 0.0460, 0.2896, 0.2969, 0.2924, 0.7538, 0.5971, 0.0058, 0.8062,\n",
      "         0.3838, 0.0946, 0.9118, 0.6873, 0.9220, 0.3024, 0.2468, 0.2095, 0.5070,\n",
      "         0.6059, 0.3747, 0.6300, 0.8308, 0.1317]]), 'x': tensor([[ 3.0091e-01,  2.2841e-01, -1.5263e+00, -4.3858e-01,  4.0481e-01,\n",
      "          1.9924e-01, -2.9848e-01, -6.6388e-01,  1.7360e+00,  6.8969e-01,\n",
      "         -3.8596e-02, -4.7141e-01,  5.7094e-02, -8.0997e-01,  1.7582e+00,\n",
      "         -3.8548e-01, -3.8982e-01, -3.9959e-01,  7.9009e-02,  1.0044e-01],\n",
      "        [-4.4532e-01,  4.9004e-01, -9.7088e-02,  1.2052e+00,  9.3754e-01,\n",
      "         -2.1739e-02, -9.2189e-02,  2.9534e-01,  1.2814e+00,  8.8136e-01,\n",
      "         -7.0057e-01,  2.8812e-01,  1.3943e-03, -7.3265e-01,  1.2999e-01,\n",
      "         -3.2721e-01, -5.3804e-01, -9.1539e-02,  3.9023e-02, -6.4893e-01]])}\n"
     ]
    }
   ],
   "source": [
    "outputs = p1.sample({\"y\": y, \"a\": a})\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'y': tensor([[0.4487, 0.0598, 0.7338, 0.3522, 0.7955, 0.7567, 0.8746, 0.3631, 0.7995,\n",
       "          0.2807, 0.9368, 0.0192, 0.9368, 0.8792, 0.2240, 0.1647, 0.9051, 0.8877,\n",
       "          0.4056, 0.9226, 0.9058, 0.5873, 0.9171, 0.7015, 0.2538, 0.4920, 0.3192,\n",
       "          0.5458, 0.0588, 0.0675],\n",
       "         [0.9459, 0.8521, 0.0066, 0.4740, 0.8384, 0.5122, 0.0363, 0.2689, 0.6294,\n",
       "          0.0306, 0.6115, 0.2558, 0.4377, 0.0827, 0.0874, 0.6609, 0.6415, 0.0991,\n",
       "          0.4069, 0.6617, 0.9121, 0.0812, 0.1757, 0.2514, 0.3985, 0.0874, 0.2304,\n",
       "          0.8469, 0.6807, 0.7081]]),\n",
       " 'a': tensor([[0.2873, 0.9435, 0.1231, 0.2204, 0.6657, 0.5794, 0.0838, 0.2769, 0.6844,\n",
       "          0.1111, 0.7587, 0.8047, 0.0507, 0.9262, 0.2786, 0.1218, 0.6858, 0.6872,\n",
       "          0.2060, 0.1119, 0.5898, 0.1417, 0.5471, 0.3720, 0.8313, 0.9112, 0.6975,\n",
       "          0.7669, 0.0205, 0.5423, 0.7177, 0.6533, 0.9923, 0.3031, 0.6046, 0.6131,\n",
       "          0.2235, 0.6828, 0.2267, 0.3587, 0.8634, 0.8237, 0.4217, 0.2676, 0.1127,\n",
       "          0.1590, 0.5252, 0.5577, 0.5843, 0.3678],\n",
       "         [0.2433, 0.8302, 0.8332, 0.7060, 0.4069, 0.3686, 0.9766, 0.3705, 0.1188,\n",
       "          0.6160, 0.1727, 0.4442, 0.7902, 0.4048, 0.5020, 0.3769, 0.8155, 0.1155,\n",
       "          0.0530, 0.4988, 0.0719, 0.5762, 0.7310, 0.0912, 0.5370, 0.7789, 0.1860,\n",
       "          0.7515, 0.0460, 0.2896, 0.2969, 0.2924, 0.7538, 0.5971, 0.0058, 0.8062,\n",
       "          0.3838, 0.0946, 0.9118, 0.6873, 0.9220, 0.3024, 0.2468, 0.2095, 0.5070,\n",
       "          0.6059, 0.3747, 0.6300, 0.8308, 0.1317]]),\n",
       " 'x': tensor([[ 3.0091e-01,  2.2841e-01, -1.5263e+00, -4.3858e-01,  4.0481e-01,\n",
       "           1.9924e-01, -2.9848e-01, -6.6388e-01,  1.7360e+00,  6.8969e-01,\n",
       "          -3.8596e-02, -4.7141e-01,  5.7094e-02, -8.0997e-01,  1.7582e+00,\n",
       "          -3.8548e-01, -3.8982e-01, -3.9959e-01,  7.9009e-02,  1.0044e-01],\n",
       "         [-4.4532e-01,  4.9004e-01, -9.7088e-02,  1.2052e+00,  9.3754e-01,\n",
       "          -2.1739e-02, -9.2189e-02,  2.9534e-01,  1.2814e+00,  8.8136e-01,\n",
       "          -7.0057e-01,  2.8812e-01,  1.3943e-03, -7.3265e-01,  1.2999e-01,\n",
       "          -3.2721e-01, -5.3804e-01, -9.1539e-02,  3.9023e-02, -6.4893e-01]]),\n",
       " 'z': tensor([[-0.3043, -0.0036, -1.8203,  0.2389,  0.3397,  0.2100, -0.4356,  0.7210,\n",
       "           0.4516, -1.0480,  0.0917,  0.1845,  0.7296, -1.7125,  0.0583,  0.0710,\n",
       "          -0.3265, -0.4858, -0.9157,  0.2590],\n",
       "         [ 1.2060,  0.1144,  0.5583,  0.6647, -0.7104, -0.3290,  0.9385,  0.2185,\n",
       "          -0.2628, -0.2660,  0.6504,  1.6973,  0.2373,  0.3984,  1.1082,  1.1673,\n",
       "           0.7593,  2.1413, -0.1267,  0.1326]])}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p2.sample(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-40.4417, -34.7918], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "outputs = p3.sample({\"y\":y, \"a\":a}, batch_n=batch_n)\n",
    "print(p3.log_prob().eval(outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-155.2850, -152.5048], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "outputs = p_all.sample(batch_n=batch_n)\n",
    "print(p_all.log_prob().eval(outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
