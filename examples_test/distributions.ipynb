{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples of creating and operating distributions in Pixyz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f944c1310d0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import numpy as np\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pixyz.distributions import Normal\n",
    "from pixyz.utils import print_latex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dim = 20\n",
    "y_dim = 30\n",
    "z_dim = 40\n",
    "a_dim = 50\n",
    "batch_n = 2\n",
    "\n",
    "class P1(Normal):\n",
    "    def __init__(self):\n",
    "        super(P1, self).__init__(cond_var=[\"y\", \"a\"], var=[\"x\"], name=\"p_{1}\")\n",
    "\n",
    "        self.fc1 = nn.Linear(y_dim, 10)\n",
    "        self.fc2 = nn.Linear(a_dim, 10)\n",
    "        self.fc21 = nn.Linear(10+10, 20)\n",
    "        self.fc22 = nn.Linear(10+10, 20)\n",
    "\n",
    "    def forward(self, a, y):\n",
    "        h1 = F.relu(self.fc1(y))\n",
    "        h2 = F.relu(self.fc2(a))\n",
    "        h12 = torch.cat([h1, h2], 1)\n",
    "        return {\"loc\": self.fc21(h12), \"scale\": F.softplus(self.fc22(h12))}\n",
    "\n",
    "class P2(Normal):\n",
    "    def __init__(self):\n",
    "        super(P2, self).__init__(cond_var=[\"x\", \"y\"], var=[\"z\"], name=\"p_{2}\")\n",
    "\n",
    "        self.fc3 = nn.Linear(x_dim, 30)\n",
    "        self.fc4 = nn.Linear(30+y_dim, 400)\n",
    "        self.fc51 = nn.Linear(400, 20)\n",
    "        self.fc52 = nn.Linear(400, 20)\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        h3 = F.relu(self.fc3(x))\n",
    "        h4 = F.relu(self.fc4(torch.cat([h3, y], 1)))\n",
    "        return {\"loc\": self.fc51(h4), \"scale\": F.softplus(self.fc52(h4))}\n",
    "    \n",
    "p4 = Normal(loc=torch.tensor(0.), scale=torch.tensor(1.), var=[\"a\"], features_shape=[a_dim], name=\"p_{4}\")\n",
    "p6 = Normal(loc=torch.tensor(0.), scale=torch.tensor(1.), var=[\"y\"], features_shape=[y_dim], name=\"p_{6}\")\n",
    "    \n",
    "x = torch.from_numpy(np.random.random((batch_n, x_dim)).astype(\"float32\"))\n",
    "y = torch.from_numpy(np.random.random((batch_n, y_dim)).astype(\"float32\"))\n",
    "a = torch.from_numpy(np.random.random((batch_n, a_dim)).astype(\"float32\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = P1()\n",
    "p2 = P2()\n",
    "p3 = p2 * p1\n",
    "p3.name = \"p_{3}\"\n",
    "p5 = p3 * p4\n",
    "p5.name = \"p_{5}\"\n",
    "p_all = p1*p2*p4*p6\n",
    "p_all.name = \"p_{all}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution:\n",
      "  p_{1}(x|y,a)\n",
      "Network architecture:\n",
      "  P1(\n",
      "    name=p_{1}, distribution_name=Normal,\n",
      "    var=['x'], cond_var=['y', 'a'], input_var=['y', 'a'], features_shape=torch.Size([])\n",
      "    (fc1): Linear(in_features=30, out_features=10, bias=True)\n",
      "    (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "    (fc21): Linear(in_features=20, out_features=20, bias=True)\n",
      "    (fc22): Linear(in_features=20, out_features=20, bias=True)\n",
      "  )\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$$p_{1}(x|y,a)$$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(p1)\n",
    "print_latex(p1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution:\n",
      "  p_{2}(z|x,y)\n",
      "Network architecture:\n",
      "  P2(\n",
      "    name=p_{2}, distribution_name=Normal,\n",
      "    var=['z'], cond_var=['x', 'y'], input_var=['x', 'y'], features_shape=torch.Size([])\n",
      "    (fc3): Linear(in_features=20, out_features=30, bias=True)\n",
      "    (fc4): Linear(in_features=60, out_features=400, bias=True)\n",
      "    (fc51): Linear(in_features=400, out_features=20, bias=True)\n",
      "    (fc52): Linear(in_features=400, out_features=20, bias=True)\n",
      "  )\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$$p_{2}(z|x,y)$$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(p2)\n",
    "print_latex(p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution:\n",
      "  p_{3}(z,x|y,a) = p_{2}(z|x,y)p_{1}(x|y,a)\n",
      "Network architecture:\n",
      "  P1(\n",
      "    name=p_{1}, distribution_name=Normal,\n",
      "    var=['x'], cond_var=['y', 'a'], input_var=['y', 'a'], features_shape=torch.Size([])\n",
      "    (fc1): Linear(in_features=30, out_features=10, bias=True)\n",
      "    (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "    (fc21): Linear(in_features=20, out_features=20, bias=True)\n",
      "    (fc22): Linear(in_features=20, out_features=20, bias=True)\n",
      "  )\n",
      "  P2(\n",
      "    name=p_{2}, distribution_name=Normal,\n",
      "    var=['z'], cond_var=['x', 'y'], input_var=['x', 'y'], features_shape=torch.Size([])\n",
      "    (fc3): Linear(in_features=20, out_features=30, bias=True)\n",
      "    (fc4): Linear(in_features=60, out_features=400, bias=True)\n",
      "    (fc51): Linear(in_features=400, out_features=20, bias=True)\n",
      "    (fc52): Linear(in_features=400, out_features=20, bias=True)\n",
      "  )\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$$p_{3}(z,x|y,a) = p_{2}(z|x,y)p_{1}(x|y,a)$$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(p3)\n",
    "print_latex(p3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution:\n",
      "  p_{4}(a)\n",
      "Network architecture:\n",
      "  Normal(\n",
      "    name=p_{4}, distribution_name=Normal,\n",
      "    var=['a'], cond_var=[], input_var=[], features_shape=torch.Size([50])\n",
      "    (loc): torch.Size([1, 50])\n",
      "    (scale): torch.Size([1, 50])\n",
      "  )\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$$p_{4}(a)$$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(p4)\n",
    "print_latex(p4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution:\n",
      "  p_{5}(z,x,a|y) = p_{2}(z|x,y)p_{1}(x|y,a)p_{4}(a)\n",
      "Network architecture:\n",
      "  Normal(\n",
      "    name=p_{4}, distribution_name=Normal,\n",
      "    var=['a'], cond_var=[], input_var=[], features_shape=torch.Size([50])\n",
      "    (loc): torch.Size([1, 50])\n",
      "    (scale): torch.Size([1, 50])\n",
      "  )\n",
      "  P1(\n",
      "    name=p_{1}, distribution_name=Normal,\n",
      "    var=['x'], cond_var=['y', 'a'], input_var=['y', 'a'], features_shape=torch.Size([])\n",
      "    (fc1): Linear(in_features=30, out_features=10, bias=True)\n",
      "    (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "    (fc21): Linear(in_features=20, out_features=20, bias=True)\n",
      "    (fc22): Linear(in_features=20, out_features=20, bias=True)\n",
      "  )\n",
      "  P2(\n",
      "    name=p_{2}, distribution_name=Normal,\n",
      "    var=['z'], cond_var=['x', 'y'], input_var=['x', 'y'], features_shape=torch.Size([])\n",
      "    (fc3): Linear(in_features=20, out_features=30, bias=True)\n",
      "    (fc4): Linear(in_features=60, out_features=400, bias=True)\n",
      "    (fc51): Linear(in_features=400, out_features=20, bias=True)\n",
      "    (fc52): Linear(in_features=400, out_features=20, bias=True)\n",
      "  )\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$$p_{5}(z,x,a|y) = p_{2}(z|x,y)p_{1}(x|y,a)p_{4}(a)$$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(p5)\n",
    "print_latex(p5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution:\n",
      "  p_{all}(z,x,a,y) = p_{2}(z|x,y)p_{1}(x|y,a)p_{4}(a)p_{6}(y)\n",
      "Network architecture:\n",
      "  Normal(\n",
      "    name=p_{6}, distribution_name=Normal,\n",
      "    var=['y'], cond_var=[], input_var=[], features_shape=torch.Size([30])\n",
      "    (loc): torch.Size([1, 30])\n",
      "    (scale): torch.Size([1, 30])\n",
      "  )\n",
      "  Normal(\n",
      "    name=p_{4}, distribution_name=Normal,\n",
      "    var=['a'], cond_var=[], input_var=[], features_shape=torch.Size([50])\n",
      "    (loc): torch.Size([1, 50])\n",
      "    (scale): torch.Size([1, 50])\n",
      "  )\n",
      "  P1(\n",
      "    name=p_{1}, distribution_name=Normal,\n",
      "    var=['x'], cond_var=['y', 'a'], input_var=['y', 'a'], features_shape=torch.Size([])\n",
      "    (fc1): Linear(in_features=30, out_features=10, bias=True)\n",
      "    (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "    (fc21): Linear(in_features=20, out_features=20, bias=True)\n",
      "    (fc22): Linear(in_features=20, out_features=20, bias=True)\n",
      "  )\n",
      "  P2(\n",
      "    name=p_{2}, distribution_name=Normal,\n",
      "    var=['z'], cond_var=['x', 'y'], input_var=['x', 'y'], features_shape=torch.Size([])\n",
      "    (fc3): Linear(in_features=20, out_features=30, bias=True)\n",
      "    (fc4): Linear(in_features=60, out_features=400, bias=True)\n",
      "    (fc51): Linear(in_features=400, out_features=20, bias=True)\n",
      "    (fc52): Linear(in_features=400, out_features=20, bias=True)\n",
      "  )\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$$p_{all}(z,x,a,y) = p_{2}(z|x,y)p_{1}(x|y,a)p_{4}(a)p_{6}(y)$$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(p_all)\n",
    "print_latex(p_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> torch.Size([10, 30])\n",
      "<class 'torch.Tensor'> torch.Size([10])\n",
      "<class 'torch.Tensor'> torch.Size([10, 50])\n",
      "<class 'torch.Tensor'> torch.Size([10])\n",
      "<class 'torch.Tensor'> torch.Size([20, 20])\n",
      "<class 'torch.Tensor'> torch.Size([20])\n",
      "<class 'torch.Tensor'> torch.Size([20, 20])\n",
      "<class 'torch.Tensor'> torch.Size([20])\n",
      "<class 'torch.Tensor'> torch.Size([30, 20])\n",
      "<class 'torch.Tensor'> torch.Size([30])\n",
      "<class 'torch.Tensor'> torch.Size([400, 60])\n",
      "<class 'torch.Tensor'> torch.Size([400])\n",
      "<class 'torch.Tensor'> torch.Size([20, 400])\n",
      "<class 'torch.Tensor'> torch.Size([20])\n",
      "<class 'torch.Tensor'> torch.Size([20, 400])\n",
      "<class 'torch.Tensor'> torch.Size([20])\n"
     ]
    }
   ],
   "source": [
    "for param in p3.parameters():\n",
    "     print(type(param.data), param.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': tensor([[-1.1218, -1.1758,  0.3717,  0.7961, -0.0242,  0.3305,  1.2300, -0.8699,\n",
       "           0.4432,  0.1784, -0.6815, -0.5970,  0.7125, -1.2493, -1.8172, -0.8318,\n",
       "           0.6193,  0.2931,  0.2749,  0.0363],\n",
       "         [-0.1584, -0.5985,  0.1077,  2.1423,  0.7052,  0.5437, -0.8555,  0.4686,\n",
       "          -0.9009,  1.7566,  0.5030, -0.2366, -0.4683,  0.9158,  0.7253,  1.1668,\n",
       "           0.3656, -0.7716,  0.0998,  0.2611]])}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p1.sample({\"a\":a, \"y\":y}, return_all=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': tensor([[[ 0.2363,  0.3990,  0.0692, -0.5842,  1.4920, -1.3252,  0.9833,\n",
       "           -0.1309,  1.1616, -0.5395,  1.1062,  0.6611, -0.0148, -0.4342,\n",
       "            1.4834,  0.2732,  1.4455, -0.7009,  0.8057, -0.8664],\n",
       "          [ 2.0172,  0.1515, -0.2260,  0.4535,  0.3293,  0.8124,  0.4819,\n",
       "           -0.4917, -0.0216, -0.8234,  0.0050,  0.9981,  1.1045, -0.1657,\n",
       "            0.9829, -1.4629,  1.4324, -1.1665, -0.6037,  0.3600]],\n",
       " \n",
       "         [[ 0.4047,  0.4998,  1.1270,  0.0223, -0.0818,  0.3570,  0.0382,\n",
       "           -1.1366,  0.4775, -0.7488, -0.0467,  0.2880,  0.6136, -0.6018,\n",
       "            0.5595,  0.6272,  2.3315, -0.1531,  1.0839,  0.3354],\n",
       "          [-0.2787, -1.7961,  1.2282,  0.2017,  0.1629,  0.0798,  0.3795,\n",
       "           -1.5618,  0.1000,  0.1157, -0.6087,  0.1748, -0.8421, -0.2185,\n",
       "            0.4638,  1.1066, -1.2051,  0.1678,  0.4344,  0.3228]],\n",
       " \n",
       "         [[-0.3361,  0.0329,  0.6392, -0.2693,  0.0803, -1.3670,  0.1784,\n",
       "            0.9852,  1.2060,  0.9109, -0.4192,  1.3437, -0.1888,  0.0754,\n",
       "            0.3178,  0.4034, -1.2282,  0.0225,  0.5858, -0.2746],\n",
       "          [-1.2848, -0.0821, -0.7562,  0.1425,  0.1035,  0.6539,  0.3710,\n",
       "           -0.8888, -0.0582,  0.4455, -0.1289, -0.7071, -1.0692,  0.5364,\n",
       "           -1.1154,  0.7670,  0.8655, -0.6206, -0.2351, -1.3304]],\n",
       " \n",
       "         [[-0.2542, -0.0428, -0.6625,  0.4869,  0.8938,  1.0624,  0.2375,\n",
       "           -0.9979,  0.4462,  1.8860,  0.3509,  0.4863,  0.1608, -0.0999,\n",
       "           -0.0793, -0.6179,  0.7197,  0.2087,  0.6434,  0.5895],\n",
       "          [-0.8341, -0.1284,  0.2147, -0.2351,  0.4732, -1.7591, -0.3928,\n",
       "           -0.1448,  0.8321, -0.7913,  0.6113,  0.7138, -0.0577,  0.3877,\n",
       "            1.1505, -0.5277,  0.1556,  0.0345,  0.6472,  0.6332]],\n",
       " \n",
       "         [[-0.2076, -0.5910, -0.8290,  0.4581,  0.1367,  0.7163,  0.0454,\n",
       "            0.0281, -0.2620, -1.4092, -1.0991,  0.9280, -0.7663, -0.7323,\n",
       "            1.1217,  0.3607, -0.2721, -1.3437, -0.2316, -0.3072],\n",
       "          [ 0.8806, -0.1551,  0.9588, -0.3525,  0.3254,  0.1608, -0.0377,\n",
       "           -1.0591,  0.6494,  0.0452, -0.2903,  0.4812, -0.4823, -1.0459,\n",
       "           -1.2476,  1.2619,  1.6461, -0.6298,  0.0534, -0.3979]]])}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p1.sample({\"a\":a, \"y\":y}, sample_shape=[5], return_all=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': tensor([[0.9683, 0.0151, 0.4744, 0.6016, 0.6464, 0.3306, 0.5251, 0.4898, 0.5678,\n",
       "          0.0677, 0.0069, 0.7992, 0.1025, 0.8956, 0.1047, 0.9507, 0.7454, 0.1687,\n",
       "          0.2084, 0.5539, 0.4110, 0.7812, 0.6907, 0.8145, 0.7193, 0.2960, 0.1326,\n",
       "          0.6641, 0.9409, 0.2728, 0.1460, 0.3379, 0.8449, 0.5248, 0.6381, 0.9087,\n",
       "          0.5832, 0.9114, 0.0425, 0.5759, 0.2675, 0.1727, 0.7583, 0.9467, 0.8108,\n",
       "          0.1090, 0.5807, 0.4598, 0.4033, 0.6732],\n",
       "         [0.1867, 0.0601, 0.6697, 0.5651, 0.5856, 0.1790, 0.3660, 0.0844, 0.1551,\n",
       "          0.7289, 0.6591, 0.0059, 0.8418, 0.8162, 0.3121, 0.0367, 0.6153, 0.2835,\n",
       "          0.5682, 0.9936, 0.9931, 0.9135, 0.9406, 0.0304, 0.7227, 0.8995, 0.5438,\n",
       "          0.2197, 0.9104, 0.0571, 0.3544, 0.5923, 0.6819, 0.4499, 0.7974, 0.0223,\n",
       "          0.8558, 0.0491, 0.1000, 0.6722, 0.2084, 0.5161, 0.6107, 0.0359, 0.9278,\n",
       "          0.7299, 0.8748, 0.0903, 0.2951, 0.9971]]),\n",
       " 'y': tensor([[0.1726, 0.8717, 0.3409, 0.0083, 0.9316, 0.0753, 0.6211, 0.2979, 0.5826,\n",
       "          0.0279, 0.4268, 0.9649, 0.6165, 0.2802, 0.5397, 0.1417, 0.7223, 0.0319,\n",
       "          0.8294, 0.0267, 0.3987, 0.8499, 0.7430, 0.2817, 0.2454, 0.4912, 0.4041,\n",
       "          0.0688, 0.4532, 0.2794],\n",
       "         [0.8561, 0.7470, 0.7878, 0.6870, 0.5151, 0.1039, 0.8625, 0.9268, 0.6096,\n",
       "          0.6477, 0.3695, 0.6836, 0.6534, 0.3756, 0.3954, 0.8602, 0.2202, 0.5959,\n",
       "          0.6758, 0.0462, 0.6555, 0.9980, 0.0156, 0.0297, 0.6170, 0.4583, 0.9426,\n",
       "          0.4794, 0.4864, 0.4973]]),\n",
       " 'x': tensor([[ 1.4172, -0.5437, -1.3153,  1.2481,  0.5047, -0.0602,  1.1630, -1.1505,\n",
       "           0.2405,  1.3894, -0.3145,  0.8331,  0.4640, -1.2266,  0.0809,  0.3199,\n",
       "          -0.1102,  1.1755, -0.6320,  0.5276],\n",
       "         [ 1.0372,  0.3260,  1.1455, -0.4917,  0.4866,  0.0943, -0.0281,  0.2579,\n",
       "          -0.0667, -0.6862, -0.8929,  1.0744,  0.2665, -0.8171, -1.0535, -1.1249,\n",
       "          -0.1405, -0.2169,  1.7122, -0.7149]])}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p1.sample({\"a\":a, \"y\":y}, return_all=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\log p_{1}(x|y,a)\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$$\\log p_{1}(x|y,a)$$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p1_log_prob = p1.log_prob()\n",
    "print(p1_log_prob)\n",
    "print_latex(p1_log_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-24.9974, -25.6844], grad_fn=<SumBackward2>)\n"
     ]
    }
   ],
   "source": [
    "outputs = p1.sample({\"y\": y, \"a\": a})\n",
    "print(p1_log_prob.eval(outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-24.7590, -24.5750], grad_fn=<SumBackward2>)\n"
     ]
    }
   ],
   "source": [
    "outputs = p2.sample({\"x\":x, \"y\":y})\n",
    "print(p2.log_prob().eval(outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'y': tensor([[0.1726, 0.8717, 0.3409, 0.0083, 0.9316, 0.0753, 0.6211, 0.2979, 0.5826,\n",
      "         0.0279, 0.4268, 0.9649, 0.6165, 0.2802, 0.5397, 0.1417, 0.7223, 0.0319,\n",
      "         0.8294, 0.0267, 0.3987, 0.8499, 0.7430, 0.2817, 0.2454, 0.4912, 0.4041,\n",
      "         0.0688, 0.4532, 0.2794],\n",
      "        [0.8561, 0.7470, 0.7878, 0.6870, 0.5151, 0.1039, 0.8625, 0.9268, 0.6096,\n",
      "         0.6477, 0.3695, 0.6836, 0.6534, 0.3756, 0.3954, 0.8602, 0.2202, 0.5959,\n",
      "         0.6758, 0.0462, 0.6555, 0.9980, 0.0156, 0.0297, 0.6170, 0.4583, 0.9426,\n",
      "         0.4794, 0.4864, 0.4973]]), 'a': tensor([[0.9683, 0.0151, 0.4744, 0.6016, 0.6464, 0.3306, 0.5251, 0.4898, 0.5678,\n",
      "         0.0677, 0.0069, 0.7992, 0.1025, 0.8956, 0.1047, 0.9507, 0.7454, 0.1687,\n",
      "         0.2084, 0.5539, 0.4110, 0.7812, 0.6907, 0.8145, 0.7193, 0.2960, 0.1326,\n",
      "         0.6641, 0.9409, 0.2728, 0.1460, 0.3379, 0.8449, 0.5248, 0.6381, 0.9087,\n",
      "         0.5832, 0.9114, 0.0425, 0.5759, 0.2675, 0.1727, 0.7583, 0.9467, 0.8108,\n",
      "         0.1090, 0.5807, 0.4598, 0.4033, 0.6732],\n",
      "        [0.1867, 0.0601, 0.6697, 0.5651, 0.5856, 0.1790, 0.3660, 0.0844, 0.1551,\n",
      "         0.7289, 0.6591, 0.0059, 0.8418, 0.8162, 0.3121, 0.0367, 0.6153, 0.2835,\n",
      "         0.5682, 0.9936, 0.9931, 0.9135, 0.9406, 0.0304, 0.7227, 0.8995, 0.5438,\n",
      "         0.2197, 0.9104, 0.0571, 0.3544, 0.5923, 0.6819, 0.4499, 0.7974, 0.0223,\n",
      "         0.8558, 0.0491, 0.1000, 0.6722, 0.2084, 0.5161, 0.6107, 0.0359, 0.9278,\n",
      "         0.7299, 0.8748, 0.0903, 0.2951, 0.9971]]), 'x': tensor([[ 2.9297e-01,  2.9912e-01, -1.6755e+00, -4.5636e-01,  5.5452e-01,\n",
      "          1.2961e-01, -2.6550e-01, -6.0425e-01,  1.6860e+00,  7.7367e-01,\n",
      "          1.6184e-01, -4.1869e-01,  4.6933e-02, -8.8394e-01,  1.6136e+00,\n",
      "         -4.4621e-01, -3.9883e-01, -2.7835e-01, -1.9361e-03,  7.9823e-02],\n",
      "        [-3.1197e-01,  4.8953e-01, -5.4717e-04,  1.1795e+00,  1.0597e+00,\n",
      "          2.3813e-02, -1.0905e-02,  2.8811e-01,  1.1959e+00,  8.1312e-01,\n",
      "         -6.2378e-01,  4.1642e-01,  3.9579e-02, -5.4602e-01,  1.4652e-01,\n",
      "         -3.1701e-01, -4.9015e-01, -1.7217e-01,  1.1306e-01, -5.6934e-01]])}\n"
     ]
    }
   ],
   "source": [
    "outputs = p1.sample({\"y\": y, \"a\": a})\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'y': tensor([[0.1726, 0.8717, 0.3409, 0.0083, 0.9316, 0.0753, 0.6211, 0.2979, 0.5826,\n",
       "          0.0279, 0.4268, 0.9649, 0.6165, 0.2802, 0.5397, 0.1417, 0.7223, 0.0319,\n",
       "          0.8294, 0.0267, 0.3987, 0.8499, 0.7430, 0.2817, 0.2454, 0.4912, 0.4041,\n",
       "          0.0688, 0.4532, 0.2794],\n",
       "         [0.8561, 0.7470, 0.7878, 0.6870, 0.5151, 0.1039, 0.8625, 0.9268, 0.6096,\n",
       "          0.6477, 0.3695, 0.6836, 0.6534, 0.3756, 0.3954, 0.8602, 0.2202, 0.5959,\n",
       "          0.6758, 0.0462, 0.6555, 0.9980, 0.0156, 0.0297, 0.6170, 0.4583, 0.9426,\n",
       "          0.4794, 0.4864, 0.4973]]),\n",
       " 'a': tensor([[0.9683, 0.0151, 0.4744, 0.6016, 0.6464, 0.3306, 0.5251, 0.4898, 0.5678,\n",
       "          0.0677, 0.0069, 0.7992, 0.1025, 0.8956, 0.1047, 0.9507, 0.7454, 0.1687,\n",
       "          0.2084, 0.5539, 0.4110, 0.7812, 0.6907, 0.8145, 0.7193, 0.2960, 0.1326,\n",
       "          0.6641, 0.9409, 0.2728, 0.1460, 0.3379, 0.8449, 0.5248, 0.6381, 0.9087,\n",
       "          0.5832, 0.9114, 0.0425, 0.5759, 0.2675, 0.1727, 0.7583, 0.9467, 0.8108,\n",
       "          0.1090, 0.5807, 0.4598, 0.4033, 0.6732],\n",
       "         [0.1867, 0.0601, 0.6697, 0.5651, 0.5856, 0.1790, 0.3660, 0.0844, 0.1551,\n",
       "          0.7289, 0.6591, 0.0059, 0.8418, 0.8162, 0.3121, 0.0367, 0.6153, 0.2835,\n",
       "          0.5682, 0.9936, 0.9931, 0.9135, 0.9406, 0.0304, 0.7227, 0.8995, 0.5438,\n",
       "          0.2197, 0.9104, 0.0571, 0.3544, 0.5923, 0.6819, 0.4499, 0.7974, 0.0223,\n",
       "          0.8558, 0.0491, 0.1000, 0.6722, 0.2084, 0.5161, 0.6107, 0.0359, 0.9278,\n",
       "          0.7299, 0.8748, 0.0903, 0.2951, 0.9971]]),\n",
       " 'x': tensor([[ 2.9297e-01,  2.9912e-01, -1.6755e+00, -4.5636e-01,  5.5452e-01,\n",
       "           1.2961e-01, -2.6550e-01, -6.0425e-01,  1.6860e+00,  7.7367e-01,\n",
       "           1.6184e-01, -4.1869e-01,  4.6933e-02, -8.8394e-01,  1.6136e+00,\n",
       "          -4.4621e-01, -3.9883e-01, -2.7835e-01, -1.9361e-03,  7.9823e-02],\n",
       "         [-3.1197e-01,  4.8953e-01, -5.4717e-04,  1.1795e+00,  1.0597e+00,\n",
       "           2.3813e-02, -1.0905e-02,  2.8811e-01,  1.1959e+00,  8.1312e-01,\n",
       "          -6.2378e-01,  4.1642e-01,  3.9579e-02, -5.4602e-01,  1.4652e-01,\n",
       "          -3.1701e-01, -4.9015e-01, -1.7217e-01,  1.1306e-01, -5.6934e-01]]),\n",
       " 'z': tensor([[-0.3553,  0.0194, -1.7235,  0.2244,  0.5014,  0.1733, -0.4645,  0.6988,\n",
       "           0.3512, -0.9579,  0.2001,  0.1296,  0.5815, -1.6145,  0.0640,  0.0372,\n",
       "          -0.2413, -0.5274, -0.9552,  0.2157],\n",
       "         [ 1.4041,  0.1068,  0.5696,  0.7542, -0.6859, -0.3653,  0.8612,  0.2095,\n",
       "          -0.1896, -0.3342,  0.7291,  1.7224,  0.2547,  0.5343,  1.2968,  1.2112,\n",
       "           0.8615,  2.0232, -0.1655,  0.2294]])}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p2.sample(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-40.1329, -34.7207], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "outputs = p3.sample({\"y\":y, \"a\":a}, batch_n=batch_n)\n",
    "print(p3.log_prob().eval(outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-155.2850, -152.5049], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "outputs = p_all.sample(batch_n=batch_n)\n",
    "print(p_all.log_prob().eval(outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
