{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples of creating and operating distributions in Pixyz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f3ab00939d0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import numpy as np\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pixyz.distributions import Normal\n",
    "from pixyz.utils import print_latex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dim = 20\n",
    "y_dim = 30\n",
    "z_dim = 40\n",
    "a_dim = 50\n",
    "batch_n = 2\n",
    "\n",
    "class P1(Normal):\n",
    "    def __init__(self):\n",
    "        super(P1, self).__init__(cond_var=[\"y\", \"a\"], var=[\"x\"], name=\"p_{1}\")\n",
    "\n",
    "        self.fc1 = nn.Linear(y_dim, 10)\n",
    "        self.fc2 = nn.Linear(a_dim, 10)\n",
    "        self.fc21 = nn.Linear(10+10, 20)\n",
    "        self.fc22 = nn.Linear(10+10, 20)\n",
    "\n",
    "    def forward(self, a, y):\n",
    "        h1 = F.relu(self.fc1(y))\n",
    "        h2 = F.relu(self.fc2(a))\n",
    "        h12 = torch.cat([h1, h2], 1)\n",
    "        return {\"loc\": self.fc21(h12), \"scale\": F.softplus(self.fc22(h12))}\n",
    "\n",
    "class P2(Normal):\n",
    "    def __init__(self):\n",
    "        super(P2, self).__init__(cond_var=[\"x\", \"y\"], var=[\"z\"], name=\"p_{2}\")\n",
    "\n",
    "        self.fc3 = nn.Linear(x_dim, 30)\n",
    "        self.fc4 = nn.Linear(30+y_dim, 400)\n",
    "        self.fc51 = nn.Linear(400, 20)\n",
    "        self.fc52 = nn.Linear(400, 20)\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        h3 = F.relu(self.fc3(x))\n",
    "        h4 = F.relu(self.fc4(torch.cat([h3, y], 1)))\n",
    "        return {\"loc\": self.fc51(h4), \"scale\": F.softplus(self.fc52(h4))}\n",
    "    \n",
    "p4 = Normal(loc=torch.tensor(0.), scale=torch.tensor(1.), var=[\"a\"], features_shape=[a_dim], name=\"p_{4}\")\n",
    "p6 = Normal(loc=torch.tensor(0.), scale=torch.tensor(1.), var=[\"y\"], features_shape=[y_dim], name=\"p_{6}\")\n",
    "    \n",
    "x = torch.from_numpy(np.random.random((batch_n, x_dim)).astype(\"float32\"))\n",
    "y = torch.from_numpy(np.random.random((batch_n, y_dim)).astype(\"float32\"))\n",
    "a = torch.from_numpy(np.random.random((batch_n, a_dim)).astype(\"float32\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = P1()\n",
    "p2 = P2()\n",
    "p3 = p2 * p1\n",
    "p3.name = \"p_{3}\"\n",
    "p5 = p3 * p4\n",
    "p5.name = \"p_{5}\"\n",
    "p_all = p1*p2*p4*p6\n",
    "p_all.name = \"p_{all}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution:\n",
      "  p_{1}(x|y,a)\n",
      "Network architecture:\n",
      "  P1(\n",
      "    name=p_{1}, distribution_name=Normal,\n",
      "    var=['x'], cond_var=['y', 'a'], input_var=['y', 'a'], features_shape=torch.Size([])\n",
      "    (fc1): Linear(in_features=30, out_features=10, bias=True)\n",
      "    (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "    (fc21): Linear(in_features=20, out_features=20, bias=True)\n",
      "    (fc22): Linear(in_features=20, out_features=20, bias=True)\n",
      "  )\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle p_{1}(x|y,a)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(p1)\n",
    "print_latex(p1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution:\n",
      "  p_{2}(z|x,y)\n",
      "Network architecture:\n",
      "  P2(\n",
      "    name=p_{2}, distribution_name=Normal,\n",
      "    var=['z'], cond_var=['x', 'y'], input_var=['x', 'y'], features_shape=torch.Size([])\n",
      "    (fc3): Linear(in_features=20, out_features=30, bias=True)\n",
      "    (fc4): Linear(in_features=60, out_features=400, bias=True)\n",
      "    (fc51): Linear(in_features=400, out_features=20, bias=True)\n",
      "    (fc52): Linear(in_features=400, out_features=20, bias=True)\n",
      "  )\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle p_{2}(z|x,y)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(p2)\n",
    "print_latex(p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution:\n",
      "  p_{2}(z,x|y,a) = p_{2}(z|x,y)p_{1}(x|y,a)\n",
      "Network architecture:\n",
      "  p_{1}(x|y,a):\n",
      "  P1(\n",
      "    name=p_{1}, distribution_name=Normal,\n",
      "    var=['x'], cond_var=['y', 'a'], input_var=['y', 'a'], features_shape=torch.Size([])\n",
      "    (fc1): Linear(in_features=30, out_features=10, bias=True)\n",
      "    (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "    (fc21): Linear(in_features=20, out_features=20, bias=True)\n",
      "    (fc22): Linear(in_features=20, out_features=20, bias=True)\n",
      "  )\n",
      "  p_{2}(z|x,y):\n",
      "  P2(\n",
      "    name=p_{2}, distribution_name=Normal,\n",
      "    var=['z'], cond_var=['x', 'y'], input_var=['x', 'y'], features_shape=torch.Size([])\n",
      "    (fc3): Linear(in_features=20, out_features=30, bias=True)\n",
      "    (fc4): Linear(in_features=60, out_features=400, bias=True)\n",
      "    (fc51): Linear(in_features=400, out_features=20, bias=True)\n",
      "    (fc52): Linear(in_features=400, out_features=20, bias=True)\n",
      "  )\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle p_{2}(z,x|y,a) = p_{2}(z|x,y)p_{1}(x|y,a)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(p3)\n",
    "print_latex(p3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution:\n",
      "  p_{4}(a)\n",
      "Network architecture:\n",
      "  Normal(\n",
      "    name=p_{4}, distribution_name=Normal,\n",
      "    var=['a'], cond_var=[], input_var=[], features_shape=torch.Size([50])\n",
      "    (loc): torch.Size([1, 50])\n",
      "    (scale): torch.Size([1, 50])\n",
      "  )\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle p_{4}(a)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(p4)\n",
    "print_latex(p4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution:\n",
      "  p_{2}(z,x,a|y) = p_{2}(z|x,y)p_{1}(x|y,a)p_{4}(a)\n",
      "Network architecture:\n",
      "  p_{4}(a):\n",
      "  Normal(\n",
      "    name=p_{4}, distribution_name=Normal,\n",
      "    var=['a'], cond_var=[], input_var=[], features_shape=torch.Size([50])\n",
      "    (loc): torch.Size([1, 50])\n",
      "    (scale): torch.Size([1, 50])\n",
      "  )\n",
      "  p_{1}(x|y,a):\n",
      "  P1(\n",
      "    name=p_{1}, distribution_name=Normal,\n",
      "    var=['x'], cond_var=['y', 'a'], input_var=['y', 'a'], features_shape=torch.Size([])\n",
      "    (fc1): Linear(in_features=30, out_features=10, bias=True)\n",
      "    (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "    (fc21): Linear(in_features=20, out_features=20, bias=True)\n",
      "    (fc22): Linear(in_features=20, out_features=20, bias=True)\n",
      "  )\n",
      "  p_{2}(z|x,y):\n",
      "  P2(\n",
      "    name=p_{2}, distribution_name=Normal,\n",
      "    var=['z'], cond_var=['x', 'y'], input_var=['x', 'y'], features_shape=torch.Size([])\n",
      "    (fc3): Linear(in_features=20, out_features=30, bias=True)\n",
      "    (fc4): Linear(in_features=60, out_features=400, bias=True)\n",
      "    (fc51): Linear(in_features=400, out_features=20, bias=True)\n",
      "    (fc52): Linear(in_features=400, out_features=20, bias=True)\n",
      "  )\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle p_{2}(z,x,a|y) = p_{2}(z|x,y)p_{1}(x|y,a)p_{4}(a)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(p5)\n",
    "print_latex(p5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution:\n",
      "  p_{1}(x,y,a,z) = p_{2}(z|x,y)p_{1}(x|y,a)p_{4}(a)p_{6}(y)\n",
      "Network architecture:\n",
      "  p_{6}(y):\n",
      "  Normal(\n",
      "    name=p_{6}, distribution_name=Normal,\n",
      "    var=['y'], cond_var=[], input_var=[], features_shape=torch.Size([30])\n",
      "    (loc): torch.Size([1, 30])\n",
      "    (scale): torch.Size([1, 30])\n",
      "  )\n",
      "  p_{4}(a):\n",
      "  Normal(\n",
      "    name=p_{4}, distribution_name=Normal,\n",
      "    var=['a'], cond_var=[], input_var=[], features_shape=torch.Size([50])\n",
      "    (loc): torch.Size([1, 50])\n",
      "    (scale): torch.Size([1, 50])\n",
      "  )\n",
      "  p_{1}(x|y,a):\n",
      "  P1(\n",
      "    name=p_{1}, distribution_name=Normal,\n",
      "    var=['x'], cond_var=['y', 'a'], input_var=['y', 'a'], features_shape=torch.Size([])\n",
      "    (fc1): Linear(in_features=30, out_features=10, bias=True)\n",
      "    (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "    (fc21): Linear(in_features=20, out_features=20, bias=True)\n",
      "    (fc22): Linear(in_features=20, out_features=20, bias=True)\n",
      "  )\n",
      "  p_{2}(z|x,y):\n",
      "  P2(\n",
      "    name=p_{2}, distribution_name=Normal,\n",
      "    var=['z'], cond_var=['x', 'y'], input_var=['x', 'y'], features_shape=torch.Size([])\n",
      "    (fc3): Linear(in_features=20, out_features=30, bias=True)\n",
      "    (fc4): Linear(in_features=60, out_features=400, bias=True)\n",
      "    (fc51): Linear(in_features=400, out_features=20, bias=True)\n",
      "    (fc52): Linear(in_features=400, out_features=20, bias=True)\n",
      "  )\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle p_{1}(x,y,a,z) = p_{2}(z|x,y)p_{1}(x|y,a)p_{4}(a)p_{6}(y)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(p_all)\n",
    "print_latex(p_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> torch.Size([30, 20])\n",
      "<class 'torch.Tensor'> torch.Size([30])\n",
      "<class 'torch.Tensor'> torch.Size([400, 60])\n",
      "<class 'torch.Tensor'> torch.Size([400])\n",
      "<class 'torch.Tensor'> torch.Size([20, 400])\n",
      "<class 'torch.Tensor'> torch.Size([20])\n",
      "<class 'torch.Tensor'> torch.Size([20, 400])\n",
      "<class 'torch.Tensor'> torch.Size([20])\n",
      "<class 'torch.Tensor'> torch.Size([10, 30])\n",
      "<class 'torch.Tensor'> torch.Size([10])\n",
      "<class 'torch.Tensor'> torch.Size([10, 50])\n",
      "<class 'torch.Tensor'> torch.Size([10])\n",
      "<class 'torch.Tensor'> torch.Size([20, 20])\n",
      "<class 'torch.Tensor'> torch.Size([20])\n",
      "<class 'torch.Tensor'> torch.Size([20, 20])\n",
      "<class 'torch.Tensor'> torch.Size([20])\n"
     ]
    }
   ],
   "source": [
    "for param in p3.parameters():\n",
    "     print(type(param.data), param.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': tensor([[-1.0299, -1.2263,  0.5289,  0.9194, -0.2101,  0.2768,  1.3235, -0.8458,\n",
       "           0.3476,  0.0318, -0.7057, -0.5483,  0.6671, -0.8597, -1.7904, -0.8084,\n",
       "           0.6117,  0.2948,  0.3227, -0.0383],\n",
       "         [-0.3045, -0.6468,  0.0891,  2.2200,  0.5947,  0.5854, -0.9290,  0.4790,\n",
       "          -0.7963,  1.9300,  0.5019, -0.2916, -0.5468,  0.7446,  0.8173,  1.0218,\n",
       "           0.2750, -0.7355,  0.1038,  0.1159]])}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p1.sample({\"a\":a, \"y\":y}, return_all=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': tensor([[[ 1.8714e-01,  3.6696e-01,  2.1010e-01, -5.5118e-01,  1.2658e+00,\n",
       "           -1.3178e+00,  1.0771e+00, -1.3143e-01,  1.0405e+00, -7.2369e-01,\n",
       "            9.5043e-01,  6.9438e-01, -6.4541e-02, -1.1016e-01,  1.4737e+00,\n",
       "            3.0139e-01,  1.4404e+00, -7.8267e-01,  8.4115e-01, -9.3408e-01],\n",
       "          [ 2.0706e+00,  1.0844e-01, -2.5218e-01,  5.2909e-01,  2.5337e-01,\n",
       "            8.5192e-01,  3.5012e-01, -5.5830e-01,  4.4407e-02, -8.1839e-01,\n",
       "           -2.2697e-02,  1.0360e+00,  9.2339e-01, -3.9723e-01,  1.0899e+00,\n",
       "           -1.5907e+00,  1.4165e+00, -1.1127e+00, -5.8682e-01,  2.2109e-01]],\n",
       " \n",
       "         [[ 3.3799e-01,  4.6899e-01,  1.3249e+00,  9.5066e-02, -2.6627e-01,\n",
       "            3.0221e-01,  1.3340e-01, -1.1036e+00,  3.8074e-01, -9.4399e-01,\n",
       "           -1.1762e-01,  3.2594e-01,  5.6761e-01, -2.6429e-01,  5.6004e-01,\n",
       "            6.5701e-01,  2.3289e+00, -1.8887e-01,  1.1128e+00,  2.5848e-01],\n",
       "          [-4.3580e-01, -1.8528e+00,  1.2349e+00,  2.7701e-01,  1.0223e-01,\n",
       "            1.2523e-01,  2.5218e-01, -1.7141e+00,  1.6065e-01,  1.8197e-01,\n",
       "           -6.6921e-01,  1.5069e-01, -8.9624e-01, -4.5296e-01,  5.4067e-01,\n",
       "            9.6199e-01, -1.4057e+00,  1.6168e-01,  4.3223e-01,  1.8149e-01]],\n",
       " \n",
       "         [[-3.2580e-01, -3.4130e-03,  8.1077e-01, -2.1568e-01, -1.0842e-01,\n",
       "           -1.3581e+00,  2.7336e-01,  9.4737e-01,  1.0833e+00,  8.0266e-01,\n",
       "           -4.6268e-01,  1.3687e+00, -2.3955e-01,  3.5853e-01,  3.2095e-01,\n",
       "            4.3218e-01, -1.2411e+00,  1.4550e-03,  6.2641e-01, -3.4690e-01],\n",
       "          [-1.5342e+00, -1.2685e-01, -7.9442e-01,  2.1773e-01,  4.8246e-02,\n",
       "            6.9471e-01,  2.4404e-01, -9.8715e-01,  9.4037e-03,  5.3332e-01,\n",
       "           -1.6381e-01, -7.9760e-01, -1.1085e+00,  3.4401e-01, -1.1303e+00,\n",
       "            6.2456e-01,  8.0993e-01, -5.9134e-01, -2.2495e-01, -1.5777e+00]],\n",
       " \n",
       "         [[-2.5239e-01, -8.0030e-02, -5.6109e-01,  5.9003e-01,  6.8356e-01,\n",
       "            9.8164e-01,  3.3240e-01, -9.6949e-01,  3.5056e-01,  1.8287e+00,\n",
       "            2.5074e-01,  5.2175e-01,  1.1219e-01,  1.9730e-01, -7.1692e-02,\n",
       "           -5.9362e-01,  7.1247e-01,  2.0327e-01,  6.8258e-01,  5.1058e-01],\n",
       "          [-1.0422e+00, -1.7342e-01,  1.9847e-01, -1.6034e-01,  3.8399e-01,\n",
       "           -1.6989e+00, -4.8641e-01, -1.8357e-01,  8.6055e-01, -7.8409e-01,\n",
       "            6.1609e-01,  7.3027e-01, -1.6299e-01,  1.8701e-01,  1.2672e+00,\n",
       "           -6.6163e-01,  5.0335e-02,  3.4358e-02,  6.4113e-01,  5.1183e-01]],\n",
       " \n",
       "         [[-2.1070e-01, -6.3467e-01, -7.3661e-01,  5.5938e-01, -5.3515e-02,\n",
       "            6.4824e-01,  1.4059e-01,  2.2248e-02, -3.3252e-01, -1.6389e+00,\n",
       "           -1.0926e+00,  9.5802e-01, -8.2036e-01, -3.8425e-01,  1.1159e+00,\n",
       "            3.8932e-01, -2.8229e-01, -1.4793e+00, -1.7184e-01, -3.7924e-01],\n",
       "          [ 8.2975e-01, -2.0031e-01,  9.5942e-01, -2.7794e-01,  2.4978e-01,\n",
       "            2.0556e-01, -1.4685e-01, -1.1711e+00,  6.8585e-01,  1.0696e-01,\n",
       "           -3.3382e-01,  4.8015e-01, -5.5985e-01, -1.3265e+00, -1.2701e+00,\n",
       "            1.1163e+00,  1.6452e+00, -6.0010e-01,  5.8206e-02, -5.8539e-01]]])}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p1.sample({\"a\":a, \"y\":y}, sample_shape=[5], return_all=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': tensor([[0.1247, 0.3626, 0.5750, 0.3316, 0.1122, 0.2393, 0.9769, 0.6199, 0.4377,\n",
       "          0.0989, 0.6779, 0.9160, 0.0729, 0.7601, 0.6406, 0.2142, 0.1419, 0.0939,\n",
       "          0.8958, 0.6005, 0.7959, 0.5817, 0.9536, 0.6578, 0.5547, 0.4744, 0.5304,\n",
       "          0.9512, 0.9543, 0.3990, 0.5173, 0.8549, 0.4733, 0.7530, 0.6687, 0.0554,\n",
       "          0.4222, 0.7571, 0.9099, 0.3253, 0.8394, 0.0964, 0.1431, 0.4612, 0.3356,\n",
       "          0.8926, 0.5417, 0.5819, 0.7935, 0.4104],\n",
       "         [0.0295, 0.4776, 0.7399, 0.7366, 0.3285, 0.4687, 0.5953, 0.8438, 0.6898,\n",
       "          0.2132, 0.0071, 0.4417, 0.1486, 0.1484, 0.1871, 0.2375, 0.4639, 0.8257,\n",
       "          0.5834, 0.7746, 0.1868, 0.9428, 0.1989, 0.3176, 0.9830, 0.1743, 0.0506,\n",
       "          0.6278, 0.2065, 0.2463, 0.5054, 0.2877, 0.5163, 0.9787, 0.4039, 0.0271,\n",
       "          0.8808, 0.5863, 0.6645, 0.2771, 0.6532, 0.2723, 0.8658, 0.5841, 0.6185,\n",
       "          0.9491, 0.0068, 0.0945, 0.0780, 0.1591]]),\n",
       " 'y': tensor([[0.4249, 0.2331, 0.9856, 0.6609, 0.2501, 0.4779, 0.5012, 0.2993, 0.2764,\n",
       "          0.7004, 0.4063, 0.8842, 0.9118, 0.9472, 0.0198, 0.5519, 0.7312, 0.6658,\n",
       "          0.0805, 0.6665, 0.4161, 0.3674, 0.7932, 0.4358, 0.8718, 0.8125, 0.6108,\n",
       "          0.8514, 0.1534, 0.4207],\n",
       "         [0.4866, 0.2115, 0.4247, 0.6349, 0.6166, 0.3609, 0.1176, 0.6920, 0.1982,\n",
       "          0.7056, 0.2711, 0.7976, 0.0407, 0.0423, 0.3801, 0.2085, 0.1222, 0.3232,\n",
       "          0.2642, 0.4416, 0.8992, 0.8277, 0.1803, 0.3078, 0.6140, 0.9737, 0.8137,\n",
       "          0.0308, 0.3883, 0.1112]]),\n",
       " 'x': tensor([[ 1.2453e+00, -5.8679e-01, -1.2492e+00,  1.4011e+00,  3.0471e-01,\n",
       "          -9.9544e-02,  1.2566e+00, -1.1170e+00,  1.5207e-01,  1.3062e+00,\n",
       "          -3.6570e-01,  8.6436e-01,  4.1712e-01, -8.3883e-01,  8.6748e-02,\n",
       "           3.4832e-01, -1.1990e-01,  1.2512e+00, -5.6284e-01,  4.4922e-01],\n",
       "         [ 1.0007e+00,  2.8418e-01,  1.1504e+00, -4.1731e-01,  3.9617e-01,\n",
       "           1.3959e-01, -1.3771e-01,  2.5145e-01,  1.2020e-03, -6.7217e-01,\n",
       "          -9.6869e-01,  1.1180e+00,  1.4002e-01, -1.0850e+00, -1.0648e+00,\n",
       "          -1.2549e+00, -2.6653e-01, -2.0574e-01,  1.6866e+00, -9.2275e-01]])}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p1.sample({\"a\":a, \"y\":y}, return_all=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\log p_{1}(x|y,a)\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\log p_{1}(x|y,a)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p1_log_prob = p1.log_prob()\n",
    "print(p1_log_prob)\n",
    "print_latex(p1_log_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-24.8088, -25.9759], grad_fn=<SumBackward1>)\n"
     ]
    }
   ],
   "source": [
    "outputs = p1.sample({\"y\": y, \"a\": a})\n",
    "print(p1_log_prob.eval(outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-24.9166, -24.2261], grad_fn=<SumBackward1>)\n"
     ]
    }
   ],
   "source": [
    "outputs = p2.sample({\"x\":x, \"y\":y})\n",
    "print(p2.log_prob().eval(outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'y': tensor([[0.4249, 0.2331, 0.9856, 0.6609, 0.2501, 0.4779, 0.5012, 0.2993, 0.2764,\n",
      "         0.7004, 0.4063, 0.8842, 0.9118, 0.9472, 0.0198, 0.5519, 0.7312, 0.6658,\n",
      "         0.0805, 0.6665, 0.4161, 0.3674, 0.7932, 0.4358, 0.8718, 0.8125, 0.6108,\n",
      "         0.8514, 0.1534, 0.4207],\n",
      "        [0.4866, 0.2115, 0.4247, 0.6349, 0.6166, 0.3609, 0.1176, 0.6920, 0.1982,\n",
      "         0.7056, 0.2711, 0.7976, 0.0407, 0.0423, 0.3801, 0.2085, 0.1222, 0.3232,\n",
      "         0.2642, 0.4416, 0.8992, 0.8277, 0.1803, 0.3078, 0.6140, 0.9737, 0.8137,\n",
      "         0.0308, 0.3883, 0.1112]]), 'a': tensor([[0.1247, 0.3626, 0.5750, 0.3316, 0.1122, 0.2393, 0.9769, 0.6199, 0.4377,\n",
      "         0.0989, 0.6779, 0.9160, 0.0729, 0.7601, 0.6406, 0.2142, 0.1419, 0.0939,\n",
      "         0.8958, 0.6005, 0.7959, 0.5817, 0.9536, 0.6578, 0.5547, 0.4744, 0.5304,\n",
      "         0.9512, 0.9543, 0.3990, 0.5173, 0.8549, 0.4733, 0.7530, 0.6687, 0.0554,\n",
      "         0.4222, 0.7571, 0.9099, 0.3253, 0.8394, 0.0964, 0.1431, 0.4612, 0.3356,\n",
      "         0.8926, 0.5417, 0.5819, 0.7935, 0.4104],\n",
      "        [0.0295, 0.4776, 0.7399, 0.7366, 0.3285, 0.4687, 0.5953, 0.8438, 0.6898,\n",
      "         0.2132, 0.0071, 0.4417, 0.1486, 0.1484, 0.1871, 0.2375, 0.4639, 0.8257,\n",
      "         0.5834, 0.7746, 0.1868, 0.9428, 0.1989, 0.3176, 0.9830, 0.1743, 0.0506,\n",
      "         0.6278, 0.2065, 0.2463, 0.5054, 0.2877, 0.5163, 0.9787, 0.4039, 0.0271,\n",
      "         0.8808, 0.5863, 0.6645, 0.2771, 0.6532, 0.2723, 0.8658, 0.5841, 0.6185,\n",
      "         0.9491, 0.0068, 0.0945, 0.0780, 0.1591]]), 'x': tensor([[ 0.2379,  0.2659, -1.6288, -0.4149,  0.3532,  0.0833, -0.1699, -0.5890,\n",
      "          1.5463,  0.6582,  0.0756, -0.3721, -0.0024, -0.5237,  1.6024, -0.4212,\n",
      "         -0.4093, -0.3246,  0.0524,  0.0048],\n",
      "        [-0.4721,  0.4488, -0.0217,  1.2560,  0.9166,  0.0697, -0.1212,  0.2840,\n",
      "          1.2084,  0.9249, -0.6851,  0.4105, -0.0720, -0.7988,  0.2049, -0.4523,\n",
      "         -0.6407, -0.1630,  0.1168, -0.7678]])}\n"
     ]
    }
   ],
   "source": [
    "outputs = p1.sample({\"y\": y, \"a\": a})\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'y': tensor([[0.4249, 0.2331, 0.9856, 0.6609, 0.2501, 0.4779, 0.5012, 0.2993, 0.2764,\n",
       "          0.7004, 0.4063, 0.8842, 0.9118, 0.9472, 0.0198, 0.5519, 0.7312, 0.6658,\n",
       "          0.0805, 0.6665, 0.4161, 0.3674, 0.7932, 0.4358, 0.8718, 0.8125, 0.6108,\n",
       "          0.8514, 0.1534, 0.4207],\n",
       "         [0.4866, 0.2115, 0.4247, 0.6349, 0.6166, 0.3609, 0.1176, 0.6920, 0.1982,\n",
       "          0.7056, 0.2711, 0.7976, 0.0407, 0.0423, 0.3801, 0.2085, 0.1222, 0.3232,\n",
       "          0.2642, 0.4416, 0.8992, 0.8277, 0.1803, 0.3078, 0.6140, 0.9737, 0.8137,\n",
       "          0.0308, 0.3883, 0.1112]]),\n",
       " 'a': tensor([[0.1247, 0.3626, 0.5750, 0.3316, 0.1122, 0.2393, 0.9769, 0.6199, 0.4377,\n",
       "          0.0989, 0.6779, 0.9160, 0.0729, 0.7601, 0.6406, 0.2142, 0.1419, 0.0939,\n",
       "          0.8958, 0.6005, 0.7959, 0.5817, 0.9536, 0.6578, 0.5547, 0.4744, 0.5304,\n",
       "          0.9512, 0.9543, 0.3990, 0.5173, 0.8549, 0.4733, 0.7530, 0.6687, 0.0554,\n",
       "          0.4222, 0.7571, 0.9099, 0.3253, 0.8394, 0.0964, 0.1431, 0.4612, 0.3356,\n",
       "          0.8926, 0.5417, 0.5819, 0.7935, 0.4104],\n",
       "         [0.0295, 0.4776, 0.7399, 0.7366, 0.3285, 0.4687, 0.5953, 0.8438, 0.6898,\n",
       "          0.2132, 0.0071, 0.4417, 0.1486, 0.1484, 0.1871, 0.2375, 0.4639, 0.8257,\n",
       "          0.5834, 0.7746, 0.1868, 0.9428, 0.1989, 0.3176, 0.9830, 0.1743, 0.0506,\n",
       "          0.6278, 0.2065, 0.2463, 0.5054, 0.2877, 0.5163, 0.9787, 0.4039, 0.0271,\n",
       "          0.8808, 0.5863, 0.6645, 0.2771, 0.6532, 0.2723, 0.8658, 0.5841, 0.6185,\n",
       "          0.9491, 0.0068, 0.0945, 0.0780, 0.1591]]),\n",
       " 'x': tensor([[ 0.2379,  0.2659, -1.6288, -0.4149,  0.3532,  0.0833, -0.1699, -0.5890,\n",
       "           1.5463,  0.6582,  0.0756, -0.3721, -0.0024, -0.5237,  1.6024, -0.4212,\n",
       "          -0.4093, -0.3246,  0.0524,  0.0048],\n",
       "         [-0.4721,  0.4488, -0.0217,  1.2560,  0.9166,  0.0697, -0.1212,  0.2840,\n",
       "           1.2084,  0.9249, -0.6851,  0.4105, -0.0720, -0.7988,  0.2049, -0.4523,\n",
       "          -0.6407, -0.1630,  0.1168, -0.7678]]),\n",
       " 'z': tensor([[-0.3041,  0.0049, -1.7517,  0.2056,  0.3390,  0.2341, -0.4483,  0.6315,\n",
       "           0.4354, -1.0386,  0.0624,  0.1418,  0.6512, -1.6501,  0.0763,  0.0221,\n",
       "          -0.3272, -0.6403, -0.8967,  0.1917],\n",
       "         [ 1.4336,  0.0990,  0.5233,  0.6378, -0.6617, -0.3073,  0.8964,  0.2177,\n",
       "          -0.1558, -0.2609,  0.7743,  1.6716,  0.3277,  0.5224,  1.1160,  1.2614,\n",
       "           0.8027,  2.0231, -0.2338,  0.1284]])}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p2.sample(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-40.1202, -34.6922], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "outputs = p3.sample({\"y\":y, \"a\":a}, batch_n=batch_n)\n",
    "print(p3.log_prob().eval(outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-155.2850, -152.5048], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "outputs = p_all.sample(batch_n=batch_n)\n",
    "print(p_all.log_prob().eval(outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
