{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "seed = 1\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Tars.distributions import Normal, Bernoulli\n",
    "from Tars.distributions.divergences import KullbackLeibler\n",
    "from Tars.models import VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2dLSTMCell(nn.Module):\n",
    "    \"\"\"\n",
    "    2d convolutional long short-term memory (LSTM) cell.\n",
    "    Functionally equivalent to nn.LSTMCell with the\n",
    "    difference being that nn.Kinear layers are replaced\n",
    "    by nn.Conv2D layers.\n",
    "    :param in_channels: number of input channels\n",
    "    :param out_channels: number of output channels\n",
    "    :param kernel_size: size of image kernel\n",
    "    :param stride: length of kernel stride\n",
    "    :param padding: number of pixels to pad with\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1):\n",
    "        super(Conv2dLSTMCell, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "\n",
    "        kwargs = dict(kernel_size=kernel_size, stride=stride, padding=padding)\n",
    "\n",
    "        self.forget = nn.Conv2d(in_channels, out_channels, **kwargs)\n",
    "        self.input  = nn.Conv2d(in_channels, out_channels, **kwargs)\n",
    "        self.output = nn.Conv2d(in_channels, out_channels, **kwargs)\n",
    "        self.state  = nn.Conv2d(in_channels, out_channels, **kwargs)\n",
    "\n",
    "    def forward(self, input, states):\n",
    "        \"\"\"\n",
    "        Send input through the cell.\n",
    "        :param input: input to send through\n",
    "        :param states: (hidden, cell) pair of internal state\n",
    "        :return new (hidden, cell) pair\n",
    "        \"\"\"\n",
    "        (hidden, cell) = states\n",
    "\n",
    "        forget_gate = F.sigmoid(self.forget(input))\n",
    "        input_gate  = F.sigmoid(self.input(input))\n",
    "        output_gate = F.sigmoid(self.output(input))\n",
    "        state_gate  = F.tanh(self.state(input))\n",
    "\n",
    "        # Update internal cell state\n",
    "        cell = forget_gate * cell + input_gate * state_gate\n",
    "        hidden = output_gate * F.tanh(cell)\n",
    "\n",
    "        return hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dim = 3\n",
    "v_dim = 7\n",
    "h_dim = 128\n",
    "r_dim = 256\n",
    "z_dim = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inference model q(z|x_q,v_q,r)\n",
    "class Inference(Normal):\n",
    "    def __init__(self):\n",
    "        super(Inference, self).__init__(cond_var=[\"x_q\",\"v_q\", \"r\"], var=[\"z\"])\n",
    "        self.mean = nn.Conv2d(h_dim,z_dim,kernel_size=5,stride=1,padding=2)\n",
    "        self.var = nn.Conv2d(h_dim,z_dim,kernel_size=5,stride=1,padding=2)\n",
    "        \n",
    "    def forward(self, h_e):\n",
    "        return {\"loc\": self.mean(h_e), \"var\": self.var(h_e)}\n",
    "\n",
    "        \n",
    "# generative model g(x_q|z,v_q,r)\n",
    "class Generator(Normal):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__(cond_var=[\"z\",\"v_q\", \"r\"], var=[\"x_q\"])\n",
    "        self.mean = nn.Conv2d(h_dim, x_dim, kernel_size=1, stride=1, padding=0)\n",
    "    def forward(self, u, sigma_t):\n",
    "        return {\"loc\": self.mean(u), \"var\": sigma_t}\n",
    "\n",
    "        \n",
    "# prior pi(z|v_q,r)\n",
    "class Prior(Normal):\n",
    "    def __init__(self):\n",
    "        super(Prior, self).__init__(cond_var=[\"v_q\", \"r\"], var=[\"z\"])\n",
    "        self.mean = nn.Conv2d(h_dim,z_dim,kernel_size=5,stride=1,padding=2)\n",
    "        self.var = nn.Conv2d(h_dim,z_dim,kernel_size=5,stride=1,padding=2)\n",
    "        \n",
    "    def forward(self, h_g):\n",
    "        return {\"loc\": self.mean(h_g), \"var\": self.var(h_g)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pi = Prior()\n",
    "q = Inference()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'p(z|v_q,r)'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pi.prob_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'p(z|x_q,v_q,r)'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.prob_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
